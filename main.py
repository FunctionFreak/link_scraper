import asyncio
import sys
from datetime import datetime
from typing import List, Dict, Any
from scraper import GoogleScraper, BingScraper

def print_banner():
    """Print application banner"""
    print("\n" + "="*70)
    print("ğŸ” PARALLEL SEARCH SCRAPER - Google & Bing")
    print("="*70)
    print("âœ… Collects organic search results from both engines simultaneously")
    print("âŒ Filters out: AI summaries, sponsored content, ads")
    print("="*70 + "\n")

def get_user_inputs() -> Dict[str, Any]:
    """Get user inputs for search configuration"""
    # Get search query
    query = ""
    while not query.strip():
        query = input("Enter search query: ").strip()
        if not query:
            print("âš ï¸  Please enter a search query!\n")
    
    # Get number of links
    while True:
        try:
            num_links_input = input("\nNumber of links to collect per engine (default: 4): ").strip()
            if not num_links_input:
                num_links = 4
                break
            num_links = int(num_links_input)
            if num_links < 1:
                print("âš ï¸  Please enter a number greater than 0")
                continue
            break
        except ValueError:
            print("âš ï¸  Please enter a valid number")
    
    # Get debug mode
    debug_input = input("\nKeep browsers open after completion? (y/N): ").strip().lower()
    debug = debug_input in ['y', 'yes', 'true', '1']
    
    return {
        'query': query,
        'num_links': num_links,
        'debug': debug
    }

def format_results(results: List[Dict[str, Any]]) -> None:
    """Format and display the collected results with proper grouping"""
    print("\n" + "="*70)
    print("ğŸ“Š SEARCH RESULTS")
    print("="*70)
    
    # Find Google and Bing results
    google_links = []
    bing_links = []
    google_status = "NOT FOUND"
    bing_status = "NOT FOUND"
    
    for result in results:
        if result['source'] == 'Google':
            google_links = result['links'] if result['status'] == 'success' else []
            google_status = result['status']
        elif result['source'] == 'Bing':
            bing_links = result['links'] if result['status'] == 'success' else []
            bing_status = result['status']
    
    # GOOGLE RESULTS FIRST
    print(f"\nğŸ” [GOOGLE] - {google_status.upper()} ({len(google_links)} links)")
    print("-" * 70)
    
    if google_links:
        for i, link in enumerate(google_links, 1):
            print(f"\n{i}. {link['title']}")
            print(f"   ğŸ”— {link['url']}")
            print(f"   ğŸ“ {link['domain']}")
    else:
        print("\nâŒ No Google links collected")
        if google_status == 'failed':
            error_msg = next((r.get('error', 'Unknown error') for r in results if r['source'] == 'Google'), 'Unknown error')
            print(f"   Error: {error_msg}")
    
    # BING RESULTS SECOND
    print(f"\nğŸ” [BING] - {bing_status.upper()} ({len(bing_links)} links)")
    print("-" * 70)
    
    if bing_links:
        for i, link in enumerate(bing_links, 1):
            print(f"\n{i}. {link['title']}")
            print(f"   ğŸ”— {link['url']}")
            print(f"   ğŸ“ {link['domain']}")
    else:
        print("\nâŒ No Bing links collected")
        if bing_status == 'failed':
            error_msg = next((r.get('error', 'Unknown error') for r in results if r['source'] == 'Bing'), 'Unknown error')
            print(f"   Error: {error_msg}")
    
    print("\n" + "="*70)

async def run_scrapers(config: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Run both scrapers in parallel"""
    # Create scraper instances
    google_scraper = GoogleScraper(
        query=config['query'],
        num_links=config['num_links'],
        debug=config['debug']
    )
    
    bing_scraper = BingScraper(
        query=config['query'],
        num_links=config['num_links'],
        debug=config['debug']
    )
    
    print(f"\nğŸš€ Starting parallel search for: '{config['query']}'")
    print(f"ğŸ“Œ Collecting {config['num_links']} links from each engine...")
    print(f"ğŸ”§ Debug mode: {'ON' if config['debug'] else 'OFF'}")
    print("-" * 70)
    
    # Run scrapers in parallel
    start_time = datetime.now()
    
    try:
        # Run both scrapers simultaneously and wait for both to complete
        results = await asyncio.gather(
            google_scraper.run(),
            bing_scraper.run(),
            return_exceptions=True
        )
        
        # Handle any exceptions
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                source = ['Google', 'Bing'][i]
                processed_results.append({
                    'source': source,
                    'links': [],
                    'status': 'failed',
                    'error': str(result),
                    'duration': (datetime.now() - start_time).total_seconds()
                })
                print(f"[{source}Scraper] âŒ Error: {str(result)}")
            else:
                processed_results.append(result)
        
        # Ensure we have both results
        if len(processed_results) < 2:
            # Add missing results
            sources = [r.get('source', '') for r in processed_results]
            for source in ['Google', 'Bing']:
                if source not in sources:
                    processed_results.append({
                        'source': source,
                        'links': [],
                        'status': 'failed',
                        'error': 'Scraper failed to start',
                        'duration': (datetime.now() - start_time).total_seconds()
                    })
        
        print(f"\nâœ… Both scrapers completed! Collected data in {(datetime.now() - start_time).total_seconds():.2f} seconds")
        
        return processed_results
        
    except Exception as e:
        print(f"âŒ Critical error in parallel execution: {str(e)}")
        # Return error results for both
        return [
            {
                'source': 'Google',
                'links': [],
                'status': 'failed',
                'error': str(e),
                'duration': (datetime.now() - start_time).total_seconds()
            },
            {
                'source': 'Bing',
                'links': [],
                'status': 'failed',
                'error': str(e),
                'duration': (datetime.now() - start_time).total_seconds()
            }
        ]

async def main():
    """Main execution function"""
    print_banner()
    
    # Get user inputs
    config = get_user_inputs()
    
    try:
        # Show debug mode message if enabled
        if config['debug']:
            print("\nğŸ” Debug mode active - browsers will stay open after completion")
            print("âš ï¸  Close browser windows manually when done\n")
        
        # Run scrapers and get results
        results = await run_scrapers(config)
        
        # Display results immediately after both scrapers complete
        format_results(results)
        
        # Handle debug mode
        if config['debug']:
            print("\nğŸ” Debug mode: Browsers are kept open for inspection")
            print("âš ï¸  Press Ctrl+C to exit when done")
            print("ğŸ’¡ You can continue browsing the search results...")
            print("ğŸ”’ Browsers will stay open until you terminate this program")
            
            try:
                # Keep the program running indefinitely in debug mode
                print("\nâ³ Program is running... Keeping browsers alive...")
                while True:
                    await asyncio.sleep(10)  # Check every 10 seconds
            except KeyboardInterrupt:
                print("\n\nâœ… Exiting debug mode...")
                print("ğŸ’¡ Browser windows will close when the program exits")
        else:
            print("\nâœ… Search completed successfully!")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Search cancelled by user")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ Fatal error: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Program terminated by user")
    except Exception as e:
        print(f"\nâŒ Fatal error: {str(e)}")